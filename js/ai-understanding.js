/*
 * AI ç†è§£å±‚æ¨¡å—ï¼ˆSolo æ¨¡å¼ï¼‰
 * è¯´æ˜ï¼š
 * - æä¾›ç»Ÿä¸€çš„ AI æ¥å£å°è£…ï¼šè¯­ä¹‰ç†è§£ã€æ–‡æœ¬å‘é‡åŒ–ã€éŸ³é¢‘è½¬å†™ã€å›¾ç‰‡ç†è§£
 * - é»˜è®¤é€šè¿‡æœ¬åœ°ä»£ç† /api/gemini è½¬å‘åˆ° Google Geminiï¼Œé¿å…åœ¨å‰ç«¯æš´éœ²å¯†é’¥
 * - è‡ªåŠ¨é™çº§ï¼šå½“ä»£ç†ä¸å¯ç”¨æˆ–è¿”å›å¼‚å¸¸æ—¶ï¼Œä½¿ç”¨ç®€å•è§„åˆ™æ³•å›é€€
 *
 * ä½¿ç”¨ï¼š
 * - åœ¨ index.html ä¸­å¼•å…¥æœ¬è„šæœ¬åï¼Œwindow.AI å°†å¯ç”¨ï¼š
 *   window.AI.aiUnderstandRune(runeData)
 *   window.AI.generateEmbedding(text)
 *   window.AI.transcribeAudio(file)
 *   window.AI.analyzeImage({ imageUrl | dataUrl })
 */
(function(){
  // å°†ä»£ç†ç«¯å£æ”¹ä¸º 3001ï¼Œé¿å…ä¸é™æ€æœåŠ¡å™¨ (http-server) å†²çª
  const API_BASE = 'http://localhost:3001/api/gemini';
  const CHAT_MODEL = 'gemini-2.5-flash';
  const EMBED_MODEL = 'text-embedding-004';

  /**
   * ä» Gemini/OpenAI è¿”å›ä¸­æå–çº¯æ–‡æœ¬ï¼›åŒæ—¶å…¼å®¹é”™è¯¯æ¶ˆæ¯
   * @param {object} data - æ¨¡å‹åŸå§‹å“åº”
   * @returns {string} æ–‡æœ¬å†…å®¹æˆ–é”™è¯¯æè¿°
   */
  function extractText(data) {
    // è‹¥æœåŠ¡è¿”å›é”™è¯¯å¯¹è±¡ï¼Œç›´æ¥è¾“å‡ºé”™è¯¯ä¿¡æ¯ï¼Œä¾¿äºå®šä½
    if (data?.error?.message) {
      return String(data.error.message);
    }
    // OpenAI é£æ ¼
    const openai = data?.choices?.[0]?.message?.content;
    if (openai) return String(openai);
    // Gemini generateContent é£æ ¼
    const parts = data?.candidates?.[0]?.content?.parts;
    if (Array.isArray(parts)) {
      return parts.map(p => p?.text || '').filter(Boolean).join('\n');
    }
    // å…œåº•
    return '';
  }

  /**
   * Interpret rune content by calling the proxy service and returning a nine-turn schema.
   * Falls back to lightweight heuristics when the remote model fails.
   * @param {object} runeData - Partial rune payload containing text and media summaries.
   * @returns {Promise<object>} Semantic structure describing the rune.
   */
    async function aiUnderstandRune(runeData) {
    // ä¸­æ–‡è¯´æ˜ï¼šæŒ‰æ–°ç‰ˆä¹è½¬è¯­ä¹‰ç³»ç»Ÿè¿”å›å®Œæ•´ç»“æ„ï¼Œä¸¥æ ¼JSONï¼›å¤±è´¥æ—¶æ„é€ é™çº§ç»“æ„ã€‚
    try {
      const name = runeData?.name || 'æœªå‘½åç¬¦æ–‡';
      const inputContent = {
        text: runeData?.nineGrid?.content?.text || '',
        imageDesc: runeData?.nineGrid?.content?.imageDesc || '',
        audioText: runeData?.nineGrid?.content?.audioText || '',
        videoSummary: runeData?.nineGrid?.content?.videoSummary || '',
        videoFrame: runeData?.nineGrid?.content?.videoFrame || ''
      };
      const combinedText = [inputContent.text, inputContent.imageDesc, inputContent.audioText, inputContent.videoSummary]
        .filter(Boolean).join('\n');
      console.log('ğŸ§© AIç†è§£è¾“å…¥é•¿åº¦:', combinedText.length);

      const prompt = `ä½ æ˜¯ YinGAN OS çš„ç¬¦æ–‡ç”Ÿæˆæ™ºèƒ½ä½“ï¼ˆRune Builder Agentï¼‰ã€‚\n` +
        `è¯·åŸºäºä»¥ä¸‹å†…å®¹ç”Ÿæˆ\nä¸¥æ ¼JSONï¼ˆå¯è¢« JSON.parse è§£æï¼‰ï¼Œå­—æ®µå®Œæ•´ï¼Œé¡ºåºä¸ç¤ºä¾‹ä¸€è‡´ï¼š\n` +
        `å†…å®¹ï¼š\n${String(combinedText).slice(0, 1200)}\n` +
        `ç¤ºä¾‹ç»“æ„ï¼š\n` +
        `{"rune_name":"ç¬¦æ–‡åç§°","category":"ç¬¦æ–‡ç±»åˆ«","core":{"intent":"","essence":"","purpose":""},"content":{"text":"","imageDesc":"","audioText":"","videoSummary":"","videoFrame":""},"metadata":{"language":"ä¸­æ–‡","emotion":"","keywords":["a","b","c"],"summary":"","prompt":"","_fallback":false},"nine_turns":{"1_origin":"","2_form":"","3_name":"","4_meaning":"","5_function":"","6_action":"","7_tone":"","8_structure":{"modalities":["text","image","audio","video"],"embedding_type":"text-embedding-004","dimension":768},"9_evolution":{"version":"1.0","update_logic":"å½“ç¬¦æ–‡è¯­ä¹‰æ›´æ–°æ—¶è‡ªåŠ¨é‡ç”Ÿ"}},"context":{"source":"æ¨¡æ€èåˆ","references":[],"relations":[]},"status":{"parsed":true,"processed":true,"validated":true}}`;

      const doRequest = async () => {
        const r = await fetch(`${API_BASE}/generate`, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            model: CHAT_MODEL,
            messages: [
              { role: 'system', content: 'ä¸¥æ ¼JSONè¾“å‡ºï¼Œä¸è¦ä»»ä½•è§£é‡Šã€‚' },
              { role: 'user', content: prompt }
            ]
          })
        });
        const body = await r.text();
        let data;
        try { data = JSON.parse(body); } catch { data = { raw: body }; }
        return { ok: r.ok, status: r.status, data };
      };

      let resp = await doRequest();
      if (!resp.ok) {
        console.warn('âš ï¸ é¦–æ¬¡è°ƒç”¨å¤±è´¥ï¼ŒçŠ¶æ€ç :', resp.status);
        await new Promise(r => setTimeout(r, 800));
        resp = await doRequest();
      }
      if (!resp.ok) throw new Error(`Proxy error: ${resp.status}`);

      const content = extractText(resp.data) || '';
      console.log('ğŸ” Geminiå“åº”æ–‡æœ¬é¢„è§ˆ:', content.slice(0, 160));

      const tryLooseJson = (s) => {
        const start = s.indexOf('{');
        const end = s.lastIndexOf('}');
        if (start >= 0 && end > start) {
          const slice = s.slice(start, end + 1);
          try { return JSON.parse(slice); } catch { /* ignore */ }
        }
        return null;
      };

      let parsed = null;
      try { parsed = JSON.parse(content); } catch { parsed = tryLooseJson(content); }

      if (parsed && typeof parsed === 'object') {
        // è¡¥é½ç¼ºå¤±å­—æ®µ
        parsed.rune_name = parsed.rune_name || name;
        parsed.category = parsed.category || 'æœªåˆ†ç±»';
        parsed.content = parsed.content || inputContent;
        parsed.core = parsed.core || { intent: '', essence: '', purpose: '' };
        parsed.metadata = parsed.metadata || { language: 'ä¸­æ–‡', emotion: 'ä¸­æ€§', keywords: [], summary: '', prompt: '', _fallback: false };
        parsed.nine_turns = parsed.nine_turns || { "1_origin": "", "2_form": "", "3_name": parsed.rune_name, "4_meaning": "", "5_function": "", "6_action": "", "7_tone": "", "8_structure": { modalities: [], embedding_type: 'text-embedding-004', dimension: 768 }, "9_evolution": { version: '1.0', update_logic: 'å½“ç¬¦æ–‡è¯­ä¹‰æ›´æ–°æ—¶è‡ªåŠ¨é‡ç”Ÿ' } };
        parsed.context = parsed.context || { source: 'æ¨¡æ€èåˆ', references: [], relations: [] };
        parsed.status = parsed.status || { parsed: true, processed: true, validated: true };
        return parsed;
      }

      console.warn('âš ï¸ æ¨¡å‹æœªè¿”å›æœ‰æ•ˆJSONï¼Œå¯ç”¨é™çº§æ„é€ ');
      const basic = simpleTextUnderstanding(combinedText);
      const language = detectLanguage(combinedText);
      const keywords = extractKeywords(combinedText, 6);
      const modalities = ['text','image','audio','video'].filter(m => {
        if (m === 'text') return !!inputContent.text;
        if (m === 'image') return !!inputContent.imageDesc || !!inputContent.videoFrame;
        if (m === 'audio') return !!inputContent.audioText;
        if (m === 'video') return !!inputContent.videoSummary;
        return false;
      });
      const fallback = {
        rune_name: name,
        category: 'æœªåˆ†ç±»',
        core: { intent: basic.intent, essence: basic.essence, purpose: basic.purpose },
        content: inputContent,
        metadata: {
          language,
          emotion: basic.emotion,
          keywords: keywords.length ? keywords : ['ç¬¦æ–‡','è¯­ä¹‰','YinGAN'],
          summary: combinedText.slice(0, 180) || 'AIå“åº”ä¸ºç©ºæˆ–ä¸å¯è§£æ',
          prompt: (combinedText.slice(0, 120) || 'ç”Ÿæˆç›¸ä¼¼é£æ ¼ç¬¦æ–‡'),
          _fallback: true
        },
        nine_turns: {
          "1_origin": basic.intent || 'åˆ›é€ ',
          "2_form": keywords[0] || 'ç¬¦å·',
          "3_name": name,
          "4_meaning": 'å¤šæ¨¡æ€è¯­ä¹‰ç»¼åˆ',
          "5_function": 'æ¿€å‘ä¸è®°å½•è¯­ä¹‰',
          "6_action": 'è¾“å…¥ç›¸å…³ä¸»é¢˜æ—¶è§¦å‘',
          "7_tone": basic.emotion || 'ä¸­æ€§',
          "8_structure": { modalities, embedding_type: 'text-embedding-004', dimension: 768 },
          "9_evolution": { version: '1.0', update_logic: 'å½“ç¬¦æ–‡è¯­ä¹‰æ›´æ–°æ—¶è‡ªåŠ¨é‡ç”Ÿ' }
        },
        context: { source: 'æ¨¡æ€èåˆ', references: [], relations: [] },
        status: { parsed: true, processed: true, validated: false }
      };
      return fallback;
    } catch (err) {
      console.warn('aiUnderstandRune å¤±è´¥:', err);
      const plain = runeData?.nineGrid?.content?.text || '';
      const basic = simpleTextUnderstanding(plain);
      const language = detectLanguage(plain);
      const keywords = extractKeywords(plain, 6);
      return {
        rune_name: runeData?.name || 'æœªå‘½åç¬¦æ–‡',
        category: 'æœªåˆ†ç±»',
        core: { intent: basic.intent, essence: basic.essence, purpose: basic.purpose },
        content: { text: plain, imageDesc: '', audioText: '', videoSummary: '', videoFrame: '' },
        metadata: { language, emotion: basic.emotion, keywords, summary: 'AIç†è§£å¤±è´¥ï¼š' + (err?.message || String(err)), prompt: 'AIç†è§£å¤±è´¥', _fallback: true },
        nine_turns: { "1_origin": basic.intent, "2_form": keywords[0] || 'ç¬¦å·', "3_name": runeData?.name || 'æœªå‘½åç¬¦æ–‡', "4_meaning": 'ç®€æ˜“è§„åˆ™æ³•ç”Ÿæˆ', "5_function": 'å ä½', "6_action": 'æ— ', "7_tone": basic.emotion, "8_structure": { modalities: ['text'], embedding_type: 'text-embedding-004', dimension: 768 }, "9_evolution": { version: '1.0', update_logic: 'å¤±è´¥æ—¶ä¿ç•™å ä½' } },
        context: { source: 'é™çº§ç”Ÿæˆ', references: [], relations: [] },
        status: { parsed: true, processed: true, validated: false }
      };
    }
  }

  // Keyword extraction and language detection helpers used during fallback logic.
  function extractKeywords(text, maxKeywords = 8) {
    const words = String(text || '').toLowerCase()
      .replace(/[^\u4e00-\u9fff\w\s]/g, ' ')
      .split(/\s+/)
      .filter(word => word.length > 1);
    const count = {};
    words.forEach(w => { count[w] = (count[w] || 0) + 1; });
    return Object.entries(count).sort((a,b)=>b[1]-a[1])
      .slice(0, maxKeywords).map(([w])=>w);
  }

  function detectLanguage(text) {
    const chineseRegex = /[\u4e00-\u9fff]/;
    const englishRegex = /[a-zA-Z]/;
    if (chineseRegex.test(String(text))) return 'ä¸­æ–‡';
    if (englishRegex.test(String(text))) return 'è‹±æ–‡';
    return 'æœªçŸ¥';
  }


  /**
   * Request a text embedding from the proxy endpoint, returning vector data.
   * @param {string} text - Raw text used to build the embedding.
   * @returns {Promise<number[]>} Embedding vector (or empty array on failure).
   */
  async function generateEmbedding(text) {
    try {
      if (!text || !text.trim()) return [];
      const r = await fetch(`${API_BASE}/embeddings`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ content: { parts: [{ text }] } })
      });
      if (!r.ok) throw new Error(`Proxy error: ${r.status}`);
      const data = await r.json();
      const vec = data?.embedding?.values
        || data?.data?.[0]?.embedding
        || [];
      return Array.isArray(vec) ? vec : [];
    } catch (err) {
      console.warn('generateEmbedding å¤±è´¥ï¼š', err);
      return [];
    }
  }

  /**
   * Perform client-side audio transcription via the proxy service.
   * @param {File|Blob} file - Audio source to transcribe.
   * @param {object} [options] - Additional configuration for the request.
   * @returns {Promise<string>} Transcript text or an empty string on failure.
   */
  async function transcribeAudio(file, options = {}) {
    try {
      if (!file) return '';
      const fd = new FormData();
      fd.append('file', file);
      if (options.model) fd.append('model', options.model);
      if (options.prompt) fd.append('prompt', options.prompt);
      if (options.language) fd.append('language', options.language);
      const r = await fetch(`${API_BASE}/audio/transcriptions`, { method: 'POST', body: fd });
      const raw = await r.text();
      let data;
      try { data = JSON.parse(raw); } catch { data = { raw }; }
      if (!r.ok) throw new Error(`Proxy error: ${r.status} - ${extractText(data) || raw.slice(0,120)}`);
      const text = extractText(data) || data?.text || (Array.isArray(data?.segments) ? data.segments.map(s => s.text).join(' ') : '');
      console.log('ğŸ™ï¸ Audioè½¬å†™å“åº”é¢„è§ˆ:', String(text).slice(0, 160));
      return text;
    } catch (err) {
      console.warn('transcribeAudio å¤±è´¥ï¼š', err);
      return '';
    }
  }

  /**
   * Send image content to the proxy for captioning or vision understanding.
   * @param {object} options - Contains either an image URL or a base64 data URL.
   * @param {string} [options.imageUrl] - Remote image source.
   * @param {string} [options.dataUrl] - Inline base64 representation.
   * @param {string} [options.prompt] - Optional instruction forwarded to the model.
   * @returns {Promise<string>} Natural language summary produced by the AI service.
   */
  async function analyzeImage({ imageUrl, dataUrl, prompt = 'è¯·ç”¨ä¸­æ–‡æè¿°å›¾åƒä¸»è¦å†…å®¹ï¼ˆâ‰¤50å­—ï¼‰ã€‚' }) {
    try {
      const url = dataUrl || imageUrl;
      if (!url) throw new Error('æœªæä¾›å›¾åƒURLæˆ–dataUrl');
      const r = await fetch(`${API_BASE}/vision`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          model: CHAT_MODEL,
          messages: [
            {
              role: 'user',
              content: [
                { type: 'text', text: prompt },
                { type: 'image_url', image_url: { url } }
              ]
            }
          ]
        })
      });
      const raw = await r.text();
      let data;
      try { data = JSON.parse(raw); } catch { data = { raw }; }
      if (!r.ok) throw new Error(`Proxy error: ${r.status} - ${extractText(data) || raw.slice(0,120)}`);
      const content = extractText(data);
      console.log('ğŸ–¼ï¸ Visionå“åº”é¢„è§ˆ:', content.slice(0, 160));
      return content;
    } catch (err) {
      console.warn('analyzeImage å¤±è´¥ï¼š', err);
      return '';
    }
  }

  /**
   * ç®€å•è§„åˆ™æ³•ï¼šå½“ AI ä¸å¯ç”¨æ—¶çš„é™çº§
   */
  function simpleTextUnderstanding(text) {
    const plain = (text || '').trim();
    if (!plain) {
      return { intent: 'æ¢ç´¢æœªçŸ¥', essence: 'ç©ºå†…å®¹', purpose: 'å ä½', emotion: 'ä¸­æ€§' };
    }
    const pos = ['å¥½','æ£’','ä¼˜ç§€','æˆåŠŸ','å¿«ä¹','ç¾å¥½','å–œæ¬¢','çˆ±','èµ'];
    const neg = ['å','å·®','å¤±è´¥','æ‚²ä¼¤','ç—›è‹¦','è®¨åŒ','æ¨','ç³Ÿ'];
    const tech = ['AI','ç®—æ³•','ä»£ç ','ç¨‹åº','æŠ€æœ¯','æ•°æ®','æ¨¡å‹','ç³»ç»Ÿ','è®¡ç®—','ç½‘ç»œ'];
    const art = ['è‰ºæœ¯','ç¾å­¦','è®¾è®¡','åˆ›æ„','çµæ„Ÿ','è‰²å½©','ç”»é¢','éŸ³ä¹','è¯—æ­Œ','ç¾æœ¯'];

    let emotion = 'ä¸­æ€§';
    let essence = 'æ–‡æœ¬å†…å®¹';
    const hasPos = pos.some(w => plain.includes(w));
    const hasNeg = neg.some(w => plain.includes(w));
    if (hasPos && !hasNeg) emotion = 'ç§¯æ';
    else if (hasNeg && !hasPos) emotion = 'æ¶ˆæ';
    const hasTech = tech.some(w => plain.includes(w));
    const hasArt = art.some(w => plain.includes(w));
    if (hasTech) essence = 'æŠ€æœ¯å†…å®¹';
    else if (hasArt) essence = 'è‰ºæœ¯å†…å®¹';
    return { intent: 'è¡¨è¾¾ä¸åˆ†äº«', essence, purpose: 'ä¼ é€’ä¿¡æ¯æˆ–æƒ…æ„Ÿ', emotion };
  }

    // å¯¼å‡ºåˆ°å…¨å±€
  window.AI = {
    aiUnderstandRune,
    generateEmbedding,
    transcribeAudio,
    analyzeImage
  };
})();
